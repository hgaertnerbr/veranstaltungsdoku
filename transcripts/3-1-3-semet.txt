Europa und die sich langsam an heute. Jetzt andrücken wir mal einfach ein bisschen auf den Bauch, ein bisschen weniger durchsatzend. Ja, das ist ja auch noch ein bisschen langsamer. Ja, ja. Aber es ist ja auch passiert, weil die meisten Wärme, die sind in den Hals und bei den Wärmen, bei den Wärmen. Ah ja. Ja, ja, da haben sie mal die Begriffe da. Wenn es im Bereich ist, dann denkst du da ein bisschen Kontinent sozusagen veransammst. Dann sind es halt in diesem... Genau, ja, ja. Du bist ein Problem, du bist ein Problem, du bist ein Problem, du bist ein Problem. Ja, dann fangst du gleich an. Ja, dann musst du neben dem Rechenzentrum dein eigenes Rechenzentrum haben. Das ist das Problem. Das könnte alles abgeschafft werden. Wollen wir nicht. Wollen wir nicht. Ich fange mir verfügig an. Ich bin die Grüße an die Online-Mädchen. Hallo. Genau, man hört uns auch in der Online-Welt. Ja. Perfekt. Kannst du es noch anstecken? Nein, alles gut. Wir geben das eh gleich rum her. Also ich habe jetzt keine, ich hatte nicht geplant, dass ich jetzt 45 Minuten hier bespaße. Im Gegenteil, ich hatte es ja im Lightning Talk schon oder im Barcamp Pitch angedeutet. Ich möchte gerne einen Austausch machen zu den digitalen Assistenten, die uns immer mehr begleiten werden, die wir teilweise schon nutzen, unbewusst, dass es ein digitaler Assistent ist. Ich habe jetzt als Basis ganz spontan, ich bin immer wieder auf Veranstaltungen, aktuell gerade mit genau diesen Slides, intelligenter als Alexa, Siri, Google und Co., weil das werden diese digitalen Assistenten sein an der Stelle, die uns begleiten. begleiten und die erobern halt zunehmend die Arbeitswelt. Und aus unserer Sicht, Learning und Development, werden die digitalen Assistenten natürlich auch eine Riesenrolle spielen, weil sie werden genau diese Vergessenslücke, die wir alle haben, egal ob es eine Information ist, wo wir wissen, 30 Prozent der Arbeitszeit geht oft verloren, weil wir nach Informationen suchen. Diese 30 Prozent adressieren wir ja mit den digitalen Assistenten an der Stelle beziehungsweise noch besser wird es sein, tatsächlich wie eine digitale Assistent, das Next Best Action. Also was ist mein nächster Schritt, den ich tun sollte in meinem Tagesablauf, in meinem Prozess, in meiner Kundenkommunikation, in meiner Produktionsplanung, Logistikplanung, was auch immer angehen. Ich weiß noch nicht, wie ich die Slide später teile, aber irgendwie gibt es da wahrscheinlich auch eine Möglichkeit. Definitiv findet man hier auch rechts oben so einer Think Tank Learning and Friends Gruppe, die ist auf LinkedIn. Okay, machen wir dann danach irgendwie. Wo ich herzlich einlade dazu, auch in diese LinkedIn Gruppe zu kommen, weil dort tauschen wir uns seit gut drei Jahren oder sowas entsprechend aus, genau zu diesen Themen. Das ist ein Think Tank aus der Organisation Zukunft Personal, wo wir aktiv sind. Genau, dort haben wir auch eine Studie letztes Jahr gemacht. Da ging es nicht alleine um die digitalen Assistenten, aber es ist tatsächlich die Frage, wie wir den KI tatsächlich eingesetzt werden. Was ist der erwartete unerzielte Nutzen? Und dort haben wir über 300 Rückläufe bekommen, die uns da entsprechend signalisieren, wir werden die Prozesseffizienz enorm steigern. Wir werden Prozessqualitätsverbesserung haben. Wir werden die Entscheidungsfindung optimieren. Und wo wird diese KI eben eingesetzt werden? Ganz viel eben in diesen digitalen Assistenten, die dann eben unsere tägliche Arbeit entsprechend erleichtern. Da steigen wir aber nicht tiefer ein, sondern wie gesagt, ich möchte gerne die Zeit nutzen, dass wir uns hier austauschen, wo haben wir schon Erfahrung mit digitalen Assistenten, wie zum Beispiel diesem Assistenten, den Waschzettel, den nutzen wir schon seit Jahrzehnten, müssen uns aber oft eben einfach hier eine Hilfestellung geben, was bedeuten denn diese Zeichen an der Stelle, aber der Waschzettel ist eben genau da angebracht, wo wir ihn brauchen, also immer auffindbar, eindeutig und trotzdem. unauffällig an der Stelle und das werden die digitalen Assistenten auch sein. Wie gesagt, einen digitalen Assistenten nutzen wir alle, das ist das Navi. Ich glaube, keiner fährt mehr ohne Navi große Strecken oder unbekannte Strecken und die entwickeln sich ja auch rasant entsprechend weiter. Also das ist die Uralt-Version, quasi eingebaut im Auto. In der Regel spiegeln wir Google Maps in der Zwischenzeit auf diesem Screen, Aber die nächsten Schritte sind halt hier das Head-up-Display in der Frontscheibe. Hier die Frage in die Runde, wer hat es schon im Auto? Tatsächlich in der Frontscheibe drin, die Informationen. Und das ist halt eben nicht nur die Geschwindigkeit, sondern viele, viele weitere Informationen. Und das ist so die Weiterentwicklung jetzt hier. Die rechte Seite, da taucht dann wirklich in Echtzeit Pfeile auf, dass ich jetzt hier den Kreisverkehr verlassen soll, dass ich links abbiegen soll, etc. Also das Automobilwesen ist da ziemlich weit schon mit solchen Informationen. Auch das Thema Geschwindigkeit spielt hier unten eine entsprechende Rolle. Das ist ja die klassische KI-Anwendung, also eine Kamera, die scannt quasi unsere Umgebung, erkennt Verkehrszeichen und gibt uns dann Informationen. Ich fahre in der 30er-Zone, jetzt 40, dann ist oft ein rotes Ausrufezeichen dran. Oder das Auto regelt schon runter, was zum Beispiel mein Audi macht. Wenn ich im Fahrassistent-Mod fahre, dann regelt der automatische Geschwindigkeit runter und passt die an. Ich sage schon, in drei, vier, fünf Jahren wird der Strafzettel dann automatisch vom Konto abgebucht, wenn wir weiterhin schneller fahren werden. Also auch ein digitaler Assistent. Harald, wir sind gleich dabei. Ich habe noch zwei oder drei Slides und dann steigen wir voll ein in die Diskussion. Ach so, zum Navi? Ja, klar, logisch. Nur so. Bloß, dass der Unterschied zwischen dem zweiten und dritten Bild klar wird. Das zweite Bild ist ja fest statisch für euch auf dem Bildschirm von der Windschutzscheibe. Und das andere ist in der Brille und ist Augmented Reality. Das heißt, es wird wirklich live über das echte Leben sozusagen eingeblendet. Das heißt, wenn ihr mit dem Kopf bewegt, bleibt dieser Pfeil trotzdem auf der Straße. Also das ist eine völlig andere Erfahrung als dieses Head-Up-Display. Genau, also da kommen ganz coole neue Funktionalitäten entsprechend rein. Genau, also solche Hats-Up-Displays kennt man auch schon lange, hier zum Beispiel aus der Flugnavigation. Das ist der Vergleich dazu, wie wir auch Assistenten aktuell schon bauen. Und das ist das letzte Slide und dann steigen wir auch ein. Das ist ein typischer digitaler Assistent mit einer Schritt-für-Schritt-Anleitung zum Beispiel als intelligente Schicht vor dem Salesforce-System. Also wir legen quasi einen digitalen Assistenten als intelligente Schicht vor eine Geschäftsanwendung, hier zum Beispiel Salesforce und geben da eine Schritt-für-Schritt-Anleitung. Oder hier auf der rechten Seite im SAP-System quasi der digitale Assistent macht hier einfach die Currency-Conversion, wo man typischerweise eine Drittapplikation nutzen würde. Das kann der digitale Assistent erledigen. Oder hier unten als digitaler Assistent tatsächlich eine Validierung von Eingabefeldern springt hier der digitale Assistent an und sagt mir, hier verarbeitest du gerade eine doppelte E-Mail-Adresse, folgende Möglichkeiten hast du hier an der Stelle, damit umzugehen. Wir haben einen ähnlichen schönen Use Case auch noch im Gesundheitswesen, nicht in Deutschland im Einsatz und ich kann auch nicht so detailliert drüber reden, ist tatsächlich in 80 Krankenhäusern haben wir ja quasi so einen digitalen Assistent vor der Krankenakte und der liest tatsächlich entsprechend mit, was die Therapie oder die Medikamentengehabe tatsächlich ist und reagiert dann zum Beispiel drauf, wenn das falsche Medikament gegeben wird. warum das falsche Medikament an den Patienten gegeben wird und hilft da dem medizinischen Personal zum Beispiel, hier eben besser am Patienten zu arbeiten und weniger eben medizinische Fehler zu machen. Genau, bevor habe ich schon angeteasert, das sind so die Themen, die solche Assistenten tatsächlich lösen, Vergessenslücken schließen, Entscheidungsfindungen beschleunigen, tatsächlich das Learning on the Job ermöglichen, Weil so ein digitaler Assistent kann natürlich auch mal kurz eine Lerneinheit einspielen. So typischerweise eine Garantieabwicklung oder ein Beschwerdemanagement macht man nicht täglich oder eine internationale Reisekostenabrechnung. Da bekomme ich dann einfach ein kurzes Microlearning vom digitalen Assistentenangebot. Dann klick hier mal fünf Minuten, acht Minuten durch. Dann weißt du wieder, wie es entsprechend geht. Proaktiv auf potenzielle Fehler hinweisen oder Prozess Compliance auch zu unterstützen. Also wenn ich hier irgendwas, zum Beispiel ein Clip-Level, ich bestelle über 100.000 Euro, darf das aber eigentlich nicht. Das System verhindert es aber nicht. Dann kann der digitale Assistent mir sagen, hey, hast du folgende Approvals eingeholt? Wenn nicht, hier ist der Prozess, um eine Approval zu bekommen, um auch über 100.000 Euro bestellen zu können. Also die Datenqualität wird eben am Punkt des Entstehens entsprechend erhöht. Genau, das waren jetzt zehn Minuten Einleitung und jetzt würde ich mich gerne mit euch austauschen, wie die digitalen Assistenten hier uns helfen werden, weil das ist so ein bisschen, sage ich mal, die Lernkurve, die wir da entsprechend haben, die wir adressieren. Das heißt, ein neuer Prozessor zum Beispiel implementiert, eine neue Anwendung wird implementiert. Typischerweise macht man ein Training, bevor das Ding go live geht und dann je nachdem, wie wir danach agieren, können wir eben mit einem digitalen Assistenten die Performance weiter steigern und das Wissen dann entsprechend weiter ausbauen. Ja, die brauchen wir nicht. Ja, ich gebe schon mal. Ladies, what's going on? Gabriele hier. Was mich interessiert, ich habe mich für ein E-Bike interessiert. Da gibt es die prädiktive Ausschreibung. Auf deiner Fahrt schauen wir für dich voraus. Erkennen gefährliche Kreuzungen auf deiner Strecke. Wenn wir 60 Meter vor dir eine Gefahrenstelle erkennen, weisen wir dich darauf hin, dass du auf der Route sein kannst. Da habe ich mich gerade gefragt, mit dem Display von dir. Sag dir dein Display auch, Achtung, Fahrradfahrer kreuzen. Und da komme ich jetzt zu diesem Ethik-Konzept, was es eben auch für KI-Prompts eben geben sollte. Wie können wir als Gesellschaft dafür Sorge tragen, dass diese Assistenten, macht man die, gendert man die auch, also die digitalen Assistentinnen, dass die eben quasi gesellschaftlich ethisch korrekt handeln. Also nicht nur danach gucken, hey, du fährst 40, du kriegst ein Knöllchen, wenn du jetzt nicht 30 fährst, sondern auf der rechten Seite befindet sich ein Kindergarten oder Seniorenheim auf der 12. Und das ist so eine Frage, die ich mir gerade stelle, weil das ist schon ganz cool, so ein Auto zu haben. Aber letztendlich, wenn es nicht verhindert, dass ich irgendwie in Gefahrenzonen dann eben auch wirklich einfach entdrosselt werde oder eben weiß, dass ich damit Menschen schaden kann. Ja, es ist halt wieder so eingleisig entwickelt. Das beschäftigt mich jetzt gerade. Das passt genau dazu. Also mir ist gerade eingefallen, also ich glaube, man könnte das relativ schnell in Autos reinbauen. Weil wir haben die Erfahrung gemacht, wenn wir sehen, was wir durch unsere Taten sofort tun, also sofortiges Feedback kriegen. Also wenn man zu Hause eine PV-Anlage hat oder eine Heizung, die die Anzeige in der Wohnung hat und man sofort sieht, okay, Badewanne, Wasser eingelassen, so viel Öl weg. Oder so und so viel habe ich Energie verbraucht, passt man sein Verhalten in der Regel an. Nicht alle, aber die meisten passen es an. Und man könnte theoretisch im Auto eine Anzeige drin haben, die die Wahrscheinlichkeit oder die berechnete Wahrscheinlichkeit eines tödlichen Unfalls mit dem derzeitigen Verhalten koppelt. Du kannst ja im Endeffekt sagen, wenn ich mit der 30er-Zone durch den Ort fahre, kriege ich ein Knöllchen, egal. Aber wenn du an eine Keuzung kommst, kannst du ja sagen, wenn jetzt dein Fahrrad kommt, dann hast du mit 37, 87 Prozent Wahrscheinlichkeit jemanden umgebracht. Das ist ziemlich heftig. Aber das würde mit Sicherheit etwas ganz anderes machen als ein Knöllchen. Also das nur als den Bezug, dass man das ins Bewusstsein bringt, was man da eigentlich gerade macht. Man fährt nicht zu schnell. Man ist dabei, jemanden potenziell umzubringen oder eben zu schädigen. Ich würde in dieses Thema Ethik nochmal reinfahren. Du hast es so schön angekündigt mit dem Vorschlag, was ist die next best action? Und ich beschäftige mich mit dem die ganzen Zeit und bin einfach sehr überzeugt davon, dass wir diese Assistenten sowieso alle kriegen und dass die uns alle die richtigen Antworten geben und bla bla bla. Also das ist nicht eine Frage. Die Frage ist, was ist die richtige Antwort? Und zwar, wer entscheidet, dass jetzt für den Harald Schirmer jetzt gerade die next best action wäre, steh auf und kühl deinen Fuß oder bleib hier, hör zu oder wer entscheidet als Organisation, deine Next Best Action ist, du arbeitest bitte noch bis um elf, weil dann machst du Promotion oder Karriere oder wer entscheidet zu sagen, nee, geh lieber heim, weil sonst ist deine Familie nicht mehr deine. Also diese Entscheidung, gebe ich die einer Firma, meiner Firma, die dann natürlich im Interesse von Effizienz und Kosten agiert, Next Best Action, gebe ich sie meinem persönlichen Assistenten, dessen Ziel es ist, mich gesund zu machen oder vielleicht glücklich zu machen oder sowas, oder gebe ich sie einem Staat, nicht, dass ich es will, aber in China läuft es so, gebe ich es einem Staat, der sagt, ich möchte, dass die Gesellschaft sich in eine Richtung entwickelt. Also, dass es Next Best Action geben wird, das steht völlig außer Frage. Mich interessiert viel mehr, wer die Hand darauf hat, zu sagen, was ist denn die und für wen ist das die Best Action? Ja, und ich glaube, dass ein kurz eine Merkung, dass heute die großen IT-Firmen machen. Das sind die. Okay, das war der Joachim, hat mal dazwischen gerufen, passt, aber Rico hat schon eine ganze Zeit lang die Hand gehoben. Ja, ich finde die ethische Frage natürlich extrem interessant und extrem schwierig, weil wenn ich das jetzt einfach eine Stufe runternehme und ich befasse mich gerade sehr intensiv bei WordPress mit Agenten und Lernen, also wie lernt man WordPress im Endeffekt? Da dachten wir am Anfang, es ist auch ganz einfach, wir machen hier so einen Agent, der führt dich da sauber durch und dann hast du das Ding. Festgestellt haben wir, dass das überhaupt nicht funktioniert, so wie wir das gerne hätten. Aus dem Grund heraus, weil natürlich jede Webseite ist anders und du willst das natürlich gerne, du suchst eigentlich ganz was anderes und der Agent führt dich in die falsche Richtung und der Assistent bringt dir zu wenig Informationen oder zu viel Informationen und so weiter und so fort. Und da ein System zu finden, das flexibel auf die Bedürfnisse, auf die Person eingeht, weil ich kann mir jetzt auch ein Beispiel vom Auto vorstellen, ja, der Assistent sagt, hey, hier nicht mehr als 30, ich muss aber, um den Unfall zu verhindern, muss ich jetzt einfach auf 90, um zum Beispiel ein anderes Fahrzeug zu überholen oder sonst irgendwas, weil sonst kracht es. Und diese Entscheidung darf nicht bei einem Assistenten liegen, respektive der Assistent muss so flexibel sein, damit er den Menschen individuell nach den Bedürftigen, die eben gerade da sind, weitergeben. Und ich bezweifle, dass das eine KI kann. Also ich wollte auch noch was dazu sagen. Wir sind 30.000. Okay, alles klar. Das passt eben auch noch mal genau zu diesem 30er-Zone. Bei mir ist auch so eine 30er-Zone. Die ist aber von 7 Uhr bis 17.30 Uhr und von 22.00 bis 6.00 Uhr. Das heißt, ich muss immer die Zeit beachten. Also natürlich könnte ich immer 30 fahren, aber da ist natürlich immer von der 50er in die 30er wieder raus. Also das sind nur 100 Meter oder sowas. Vergesse ich das immer. Und ich weiß, dass es da ist. Und da steht immer jemand, der ein Knöllchen bekommt. Nicht immer, aber es passiert dann oft. Und ich sage, oh nein, ich wusste, ich weiß es. Und dann wäre mir die Hilfe natürlich lieb. Also das ist jetzt die Zeit. Und da ist dann vor mir auch einer, der so schnell ist. Dann fahre ich einfach im Plus mit. Also irgendwie wäre es mir eine Hilfe. Da ist halt dann die Frage, wo ist das dann ethisch? Ich weiß nicht, ob das notwendig ist. In dem, da geht es wirklich um meine eigene Entscheidung. dass ich einfach compliant sein will, aber ich es einfach vergesse. Wir haben mit den Autoassistenten angefangen und ich kann euch tatsächlich gerade ein ganz plastisches Beispiel geben. Wenn meine Tochter gestern nämlich so einen Assistenten gehabt hätte, hätte sie nicht das Auto versemmelt und gegen den Baum gefahren. Und da frage ich mich tatsächlich in dem Moment, in welcher Sekunde hätte der Assistenten Ping setzen müssen, dass sie noch hätte reagieren können. Also Spoiler, ihr ist nichts passiert. Auto ist schlott, aber ihr ist nichts passiert und der Katze, dem Auto war Gott sei Dank auch nicht. Aber trotz alledem, so ein Assistent wäre gestern nett hilfreich gewesen. Ich glaube, wir sind uns alle einig, dass wir, wenn wir die Agenten, Assistenten, und da gebe ich Harald recht, die werden kommen. Und ich baue irgendwo auch darauf, dass sie kommen werden. An welcher Stelle sind wir dann wieder verantwortlich dafür? Und vor allen Dingen, dass wir dieses kritische Hinterfragen gleichzeitig bei unseren Mitarbeitenden dann auch fördern müssen, dass die für sich selber entscheiden. Das ist zwar schön, die Antwort, aber die passt nicht, die nehme ich nicht. Ich entscheide jetzt in dem Moment selber. Also wenn man es jetzt schon absehbar anschaut, was jetzt mit den Autos jetzt passiert. Du hast jetzt im Endeffekt noch viele dumme Autos, die machen das, was du sagst. Also wenn du einfach 50 fährst, fährt das Ding 50. Dann hast du Autos, die haben eine fest einprogrammierte Karte drin, da steht halt 30 und der weiß nicht, dass das Zeiten sind. Dann hast du Autos, die lesen die Schilder und können sie interpretieren, die sagen dann 30, wenn 30 ist und 50, wenn 50 ist. Und es ist aber eigentlich schon klar, dass wir es noch erleben werden, dass wir in Autos sitzen, die einfach nur die Geschwindigkeit fahren, die vorgeschrieben ist und du vielleicht gar kein Denkrat mehr hast. Das heißt, da ist diese Frage, wer entscheidet das, die ist sowieso hinfällig, weil du kannst, also entscheiden kannst du schon, aber du kannst nicht mehr reagieren. Die Frage ist aber dann jetzt, und da bin ich, weil ich gesagt habe, ich würde das in Frage stellen. Ich höre das so oft, und wir haben es gestern gehört beim Human in the Loop und sowas. Ich glaube an dieses Konzept nicht. Schlicht und ergreifend, wenn du jetzt zehn Jahre, und ich fahre seit 1995 mit Navi, wenn du mit Navigation fährst an einen Ort, wo du dich nicht auskennst. Ich möchte den sehen, der sagt, ich bin schlauer als das Navi. Wenn du heute mit JGPT arbeitest und der dir einfach immer wieder richtig gute Antworten gibt. Ich möchte den sehen, der die ganzen App Aufwand macht, das alles nochmal nachzuprüfen, was die Skling gemacht hat. Also diese Idee, dass wir am Schluss die richtige Entscheidung treffen, die halte ich einfach für überhaupt nicht umsetzbar, weil das Zeug, es kann es und wenn es es noch nicht kann, dann kann es es demnächst. Und wir sind überhaupt nicht mehr in der Lage, erstens schnell genug, rechtzeitig, zweitens gut genug, die Zeit haben wir gar nicht. Und drittens dann noch die Verantwortung zu tragen. Das werden nämlich die Autohersteller mit den Versicherungen ausmachen müssen und nicht wir mit dem Händler. Also das sind Fragen, die für mich jetzt natürlich verständlich sind. Aber wenn ich das so mal da rein nach durchdekliniere, dann sind es nicht die Fragen von morgen. Aber ist es dann nicht umso wichtiger, dass es wirklich irgendwelche, also dass wir uns weniger mit Technologiestandards beschäftigen, sondern mit KI und Ethikstandards. Und das fehlt ja komplett. Also für mich, oder ich sehe es nicht, weil ich nicht in Eureblase drin bin. Also ich habe zumindest bei KI mitbekommen, dass die auch hier aus Jürgenberg feministische KI eben vorantreibt, was ich sehr wichtig finde, um eben quasi patriarchale Strukturen schon mal rauszubekommen oder zumindest mal zu hinterfragen, was ich zum heutigen Zeitpunkt extremst wichtig finde noch. Wichtiger, wie es noch vor zehn Jahren war, wirklich. Und genauso sehe ich es eben aber auch bei diesen KI-Agents. Wenn wir da nicht anfangen, jetzt über KI, über Ethik und Standards zu reden und zu überlegen, wie kann das geschaffen werden, dann haben wir das jetzt schon verloren und das finde ich so dramatisch an der ganzen Geschichte irgendwie. Kurz was dazu, dann gehen wir uns gleich weiter. Also da beschäftigen sich viele Leute auch damit. Also es gibt eine Charta hier in Deutschland auch, die nennt sich Human Friendly Automation Organisation. Da sind viele große Unternehmen in der Zwischenzeit schon drin, die einfach sagen, wir wollen die KI human friendly entsprechend einsetzen. Und dann natürlich ganz, ganz wichtig ist, der EU-AI-Act schreibt das tatsächlich ja auch vor. Und das ist auch eine spannende Frage, ob das in euren Unternehmen auch schon ein Thema war. Wir brauchen ja zukünftig, da hat sich jetzt so ein Begriff geprägt, einen KI-Führerschein. Also jeder Mitarbeiter, so schreibt es die EU vor, der KI anwendet, muss in KI ausgebildet sein. Und dort ist das Thema Ethik als Ausbildung tatsächlich mit drin. Da gibt es jetzt schon zig Angebote im Markt von einem zweistündigen Online, vierstündig, eintägig, mehrtägig. Da gibt es KI-Führerscheinangebote. Noch weiß die deutsche Gesetzgebung nicht, wie sie mit dieser Vorschrift umgehen wird. Aber das wird so etwas Ähnliches sein, wie ihr habt die Erste-Hilfe-Ausbilder in euren Unternehmen. Pro 200 Mitarbeiter braucht man eine Erste-Hilfe-Ausbilder. Ersthelfer, genau, genau, das Begriff habe ich gesucht. Einen Ersthelfer und das wird auch von der Berufsgenossenschaft geprüft, habt ihr eure Ersthelfer im Unternehmen und ähnlich wird es gerade diskutiert mit der KI-Ausbildung. Die Datenschutzexperten habt ihr ja auch im Unternehmen, die notwendig sind an der Stelle. Und da kommt das Thema Ethik natürlich auch mit rein und die Anwendung. Einen technologischen Fakt wollte ich kurz noch bringen. Ich finde es schade, was Harald auch gerade gesagt hat, bei der Empfehlung tatsächlich, egal aus welcher KI-Lösung wir es holen, also ich nutze hauptsächlich Publicity, da steht ja die Quellenangabe ziemlich gut immer dabei, deshalb ist Publicity meine KI der Wahl aktuell gerade. Aber wo wir tatsächlich mit dem Thema KI, und ich komme ja aus der IBM-Welt, schon vor 15 Jahren quasi an den Markt gegangen sind mit Watson, da haben wir immer die Wahrscheinlichkeit mit dazu geschrieben. Wie wahrscheinlich ist das die richtige Antwort? Und so haben wir es auch eingeführt damals 2011, als wir Jeopardy gespielt haben mit Watson. Also das Wer wird Millionär, da stand immer dran, beziehungsweise Watson hat nur reagiert, wenn die Wahrscheinlichkeit über 75 Prozent war, dass die Antwort überhaupt richtig war. Nur dann hat er in zwei bis drei Sekunden den Wasser gedrückt und dann auch die entsprechende Antwort gegeben. Ich glaube, das wäre eine wichtige zusätzliche Information, dass mir meine KI sagt, wie wahrscheinlich ist denn das die richtige Antwort? Und da komme ich eben wieder ins Gesundheitswesen und da bin ich auch der Meinung, werden die Menschen nur noch eingeschränkt entscheiden, Wenn mal ein gesundheitsdigitaler Assistent einem Arzt die Empfehlung gibt, du gibst dem jetzt Aspirin 600, weil in 98 Prozent der Fälle und in 25.000 anderen Patientensituationen war das genau die richtige Medikamentengabe, wird der Arzt nicht mehr darüber nachdenken. Also selbst Ärzte werden nicht mehr darüber nachdenken, weil die Ärzte haben es ja auch extrem schwierig. Aktuell kommen 300 neue medizinische Erkenntnisse täglich in den Markt. 300 neue medizinische Erkenntnisse täglich. Kein Arzt kann diese Daten verarbeiten. Die KI kann es ganz easy. Und das wird in diesen digitalen Assistenten im Background ablaufen dann, dass da entsprechende Empfehlungen kommen. und dann natürlich erst recht noch die Schleife und es hat übrigens in 450.000 Fällen auch schon geholfen. Oder sowas, genau. Sorry. Ja, also zum EU-Eck hast du ja schon alles gesagt, es kann was hinzuzufügen, insofern kann man sich irgendwie freuen, gerade, dass man in Europa lebt, weil die Tech-Bros in USA, die haben da ganz andere Vorstellungen und wollen es ja auch gerne, dass Europa am besten das Regulierung zurücknimmt. Insofern ist man hier noch ein bisschen in einem geschützten Raum. Das wird dann auch als Bürokratie oder unnötig wahrgenommen, je nach Position. Aber objektiv haben wir in Europa hier mehr an Regeln und mehr an diesen Versuchen, die du anmahnst, als in anderen Kontinenten aktuell. Weil du ausgerechnet noch die Medizin erwähnt hast und ausgerechnet meine Frau Medizinerin. Ich meine, letztlich ist es ja so, dass Leitlinien für Ärzte genau das machen und es ist ja häufig statistisches Wissen. Ob da jetzt 300 wirklich neue relevante Fakten pro Tag dazukommen, wage ich zu bezweifeln, weil es gibt genügend Medikamente, die verwendet werden, Off-Label-Brus und da gibt es genau diese Studien eigentlich nicht und es wird trotzdem gemacht. Insofern eher gut. Es ist eh eine statistische Wahrheit in der Medizin, alles okay. Was Patienten oder Patientinnen häufig schwerfällt, bei beiden fällt es natürlich schwer, ist die Interpretation der Wahrscheinlichkeiten. Das finde ich jetzt nochmal, wenn man von Patienten, Patientin her denkt, spannend. Wenn man sagt, du hast eine Wahrscheinlichkeit von 75%, also 99%, das ist relativ easy. Aber gerade wenn Ärzte mit Patientinnen, dann über diese Wahrscheinlichkeiten sprechen, das ist relativ schwierig zu interpretieren. Da kommen dann alle menschlichen Schwächen und Heuristiken zum Tragen. Aber de facto werden sicherlich einige medizinische Fehlempfehlungen, weil nicht jeder Arzt kennt alle Leitlinien und will sich zwar ein paar Minuten weiterreden, aber da wird es wahrscheinlich besser werden mit dem statistischen Wissen. Es wird deutlich besser werden, weil was passiert denn heute? Ich gehe zum Hausarzt, ich kriege fünf Minuten Zeit, er schaut mich gerade mal in die Augen und stochert irgendwo im Heuhaufen und hoffentlich findet er die richtige Nadel, um mir das richtige Medikament zu unterschreiben. Du hast gesagt, was wird passieren? Ich würde auch sagen, das Gefährliche an der KI ist gar nicht, dass sie die Empfehlung gibt, dass sie gut oder richtig ist, sondern die Versuchung, dass man genau die Überprüfung unterlässt. Im Zweifelsfall von dir, gar kein Ping, sondern hätte das Auto gleich bremsen sollen. Da gibt es wenig Diskussion. Aber die Gefahr in diesem ganzen Sprachraum ist immer, dass man die Überprüfung natürlich unterbleibt. Weil das ist die Versuchung und so wird es auch kommen. Ich glaube, die Gruppe ist so pessimistisch. Könntest du nochmal die Seite mit den Erwartungen aufrufen? Du hattest schon eine Studie mit den Erwartungen, was die Leute glauben, was da rauskommt. Nur für mich wollte ich nochmal anschauen, was die Quelle ist und gebe ich gerne weiter. Ich würde nochmal auf deine ursprüngliche Frage für die Session zurückkommen. Wie wichtig sind digitale Assistente? Und das mache ich mal mit einem Beispiel, was ich jetzt gerade mit einem Vorstand diskutiert habe bei uns, der sagte, ich komme gar nicht mehr hinterher, wenn ich Sitzungen habe und dann kriege ich eine Agenda, zu prüfen, was auf dieser Agenda hatten wir denn schon, was haben wir denn schon in der Vergangenheit besprochen, weil der kann ja gar nicht mehr alle Protokolle im Kopf haben. Und dann ist der hergegangen, hat sich ein Agenten gebaut, selber, der Zugriff hat auf die ganzen alten Protokolle, der Zugriff hat auf Mitschriebe von ihm und wo er einfach nur noch diese Agenda reinschmeißt für die nächste Sitzung und der Assistent ihm dann sagt, folgende Punkte hatten wir ja schon mal oder liegt nahe, dass folgende Punkte darunter zusammengefasst sind oder das damit gemeint ist und es liefert ihm auch für neue Punkte, Anhaltspunkte aus dem Internet zum Beispiel, Worum könnte es denn da gehen und wo solltest du dich denn da einlesen, damit du vorbereitet bist für diese Session? Und ich glaube, Harald, du hast gestern gesagt, mit immer mehr Wissen, was wir uns aufbauen, stellen wir fest, dass wir viel mehr Wissenslücken haben. Und ich glaube, das ist unser Hauptthema. Vor 20 Jahren konnte man wirklich noch wissen, was wurde denn die letzten Male besprochen, weil es war noch überschaubar viel und das schaffen wir heute gar nicht mehr, weil so viel auf uns einprasselt aus allen Ecken. Und diese Agenten, deswegen habe ich jetzt dieses Beispiel gemacht mit diesem ganz spezifischen Agenten, der greift nur auf ganz spezifisches Wissen zurück und liefert dann auch richtig gute Antworten, weil der hat erstmal nur die Protokolle vergangener Sitzungen. Und dieser Vorstand sagte mir, das hilft ihm enorm, sich vorzubereiten, spart ihm unglaublich viel Zeit, ist ein ganz spezifischer Einsatzzweck und ich glaube, da wird die Zukunft hingehen auf diese spezifischen Einsatzzwecke, genau wie es beim Handy mit den Apps ist. Eine App ist für einen Einsatzzweck, das weicht sich gerade auf, wenn ich mir die Google Maps App angucke, die ist ja so mächtig, aber andere Apps, die machen halt, die sind für genau einen Zweck und ich glaube, da werden die ersten Assistenten auch hingehen und hingehen müssen. Wenn ich das Thema weiterdenke in Form von, wo stehen wir denn jetzt schon, dann würde ich das sofort unterschreiben, dass die das so haben wollen. Und jetzt bin ich wieder ein bisschen frech, weil wir alle konditioniert sind zur Vereinfachung. Und wenn du ein einfaches Problem hast und nicht weißt, was es da draußen gibt und eine einfache Lösung kriegst, dann findest du das attraktiv. Dann fühlst du dich sicher, dann fühlst du dich richtig, dann passt es. Und ich würde sagen, das ist komplett respektlos unserer derzeitigen Zeit gegenüber. Warum? Weil wir leben in einer Natur. Die Natur ist divers und komplex. Wir sind Teil der Natur. Wir sind komplex. Das heißt, es gibt auf nichts auf diesem Planeten eine eindeutige Antwort, sondern die hängt immer davon ab, aus welcher Perspektive ich die ausschaue, aus welcher Ausgangssituation und welcher Ziel die Situation. Das heißt, wenn wir als Menschen jetzt nicht das, was wir mit VUCA und Bani und wie wir es alles bezeichnet haben, langsam realisieren, dass Komplexität nicht irgendwie ein vorübergehender Stresszustand ist, sondern es ist der Normalzustand, dass wir jetzt endlich anfangen, viel, viel mehr sehen zu können, noch nicht wissen und noch nicht verstehen. Aber wir kriegen, was du beschrieben hast, die Situation vorher, wo es so einfach war, war ja nicht, weil es einfach war, sondern weil wir nichts mussten. Wir hatten einfach keinen Plan und keine Ahnung. Und jetzt haben wir ein bisschen mehr Ahnung und jetzt sind wir total überfordert und hoffen, dass uns KI wieder vereinfacht. Anstelle, dass wir eigentlich jetzt lernen, als Spezies mit Komplexität umzugehen, zu verstehen, dass die neun, die ich sehe, für dich eine sechs ist und beides richtig ist. Und das für alle anderen nochmal was anderes ist. Und damit umzugehen und da die KI als wertvollen Berater, Beraterin, Assistenzfunktion zu nutzen, die mir dann sagt, sprichst du jetzt als mein Arzt, als mein Psychologe, als mein Arbeitgeber, als der Staat, als meine Tochter, als vielleicht irgendein Tier, mit dem ich heute nicht kommunizieren kann, um rauszufinden, was gibt es denn für Perspektiven und wie kann ich dann als ein intelligentes, emotional, empathisches Wesen eine Entscheidung treffen, die diese vielen gesammelten Perspektiven, die keiner alleine herausfinden kann, dann umzusetzen. Das wäre für mich so das, wo wir wachsen können. Yvonne hat noch eine Hand gehoben im Netz. Ja, ich wollte ähnliches sagen. Also ich möchte zum Beispiel anbringen, wenn wir jetzt eine medizinische Frage haben, was weiß ich, Therapie XY, dann tun solche Systeme nicht unbedingt sagen, ja, ich gucke mir jetzt nur die Blutwerte an. oder er guckt zum Beispiel auch auf das Alter. Er guckt dann, sagt er, ja, bei dem Alter oder aufs Geschlecht. Er guckt auch, was er vielleicht nicht guckt, wie der Arzt, so einen grundsätzlichen Eindruck, Fitness oder was auch immer. Ja, dann würde er praktisch nach irgendwelchen Geschlechtsaltersmerkmalen irgendeine Therapie vorschlagen. Hört sich ja jetzt ganz gut an, wenn man vielleicht das vom Geschlecht her jetzt, aber er könnte ja auch sagen, wo ist der Mensch aufgewachsen, was für ein Dialekt spricht er, ist er für so eine Therapie eigentlich, ja, wird er das durchhalten? Ich mache jetzt bewusst ein bisschen zugespitzt, aber wenn wir nicht hinterfragen die Beweggründe von so einer Entscheidung, dann geben wir das aus der Hand und dann passieren Sachen, die wir eigentlich nicht abschätzen können. Also ich finde, wir können uns nicht, da auch nicht wie mein Vorredner gesagt hat, auf diese leichte Sache ausruhen, weil wir wissen, dass KI tut praktisch so einfach ein Muster drüber legen und auch die Ethik, die man vielleicht dann dem Ganzen gibt, ist Ethik, denn haben wir alle die gleiche Ethik? Wollen wir wirklich? Sagen wir das wirklich? Der eine bremst für ein Tier, der andere nicht. Der andere sagt, Kindergarten, ja, nächster alter Mensch. Na, also da tun wir auch wieder alles über einen Kamm scheren. Einfach, weil es leichter ist. Ja, das ist der Spagat, den wir sicherlich jetzt gerade gehen müssen. Und aktuell ist ja der Ansatz immer noch, der Mensch entscheidet final. Aber da ist natürlich die Fragestellung halt irgendwann, wenn eben die KI des Öfteren die richtige Entscheidung schon vorgeschlagen hat, wie viel denken die Menschen noch nach? Die Nicole wollte was sagen. Nicole, komm dran. Also ich arbeite in einem sehr businesslastigen Bereich. Von daher werden die Agenten und die Assistenten tatsächlich eine Bereicherung sein und uns das Surfbrett geben, die Businessflut, Informationsflut einfach zu bewältigen. Aber ich stelle jetzt mal als Weiterentwicklung dessen, was du gesagt hast, Harald, die steile These auf, wer jetzt noch nicht kritisch denkt, für den ist das Ausgabemedium egal, ob sie KI ist oder die Führungskraft. Absolut. Und wir haben gestern in meiner kleinen Runde, und ich glaube, nee, war keiner bei mir dabei gewesen, beim Promptaton ausprobiert, KI als Lernagent zu nutzen. Und wir hatten uns als Lernkompetenz-Coaching ausgesucht. Ich möchte meine Coaching-Kompetenz verbessern. Was bietet sich da nicht besser an, als sich eine Supervisor zu suchen oder eine KI? Und ich habe es gestern mit der KI tatsächlich ausprobiert und ich war verblüfft, dass die KI darauf reagiert hat, bin ich zu ungenau gewesen, denn sie hat nachgewollt und nachgefragt. Und das ist die Aufgabe eines Coaches. Und da habe ich auf den Bildschirm geguckt und mich gefragt, wieso soll ich jetzt bitte noch zu einem Coach live in Person gehen? Also soweit sind doch Fragen quasi schon, dass ich schon im Grunde überlege, geht es auch virtuell, geht es auch digital? Nur mal in den Raum gestellt. Ich würde gerne diesen Gap schließen, ganz kurz, weil Sie gesagt haben, in den Leitlinien ganz kurz. Also ich habe ja nicht gesagt, dass es ausreichend ist, diese Leitlinien zu verwenden. Ich habe nur gesagt, das, was eben hier in der KI statistisch repräsentiert ist, sind Leitlinien. Ein guter Arzt, eine gute Ärztin wird ja genau die angemahnten Faktoren mit einbeziehen. Also kann der oder die Person die Therapie machen, wie schätze ich der ein? Das Gegenargument ist, dass diese Information die KI nicht hat. Das ist einfach die Argumentation. Der Arzt kann heute noch, wenn du als Mensch vor ihm sitzt, Sachen einbeziehen. Diese Information hat die KI halt nicht. Also es ist auch kein Widerspruch. Ich mache jetzt noch ganz kurz ein Gruselkabinett auf. Ich habe mich nämlich gestern mit Epigenetik beschäftigt und mit Markern, die an und ausgeschalten werden, was Stressresilienz und Problemlösung und so weiter, Problemlösungsfähigkeit etc. betrifft. Und habe dann eben auch so die Abfrage gemacht, was könnte ein Worst Case passieren? Was ist ein Horrorszenario? Und dann kam so als Beispiel neue Formen von biologischer Diskriminierung. Ein Beispiel, in den USA wird diskutiert, ob epigenetische Marker zum Beispiel für Stress in Versicherungsmodelle einfließen sollen. Das heißt, dass soziale Merkmale, wo bist du aufgewachsen? In wie viel Generation wohnst du in dieser Gegend? Wer waren deine Großeltern? Was haben die gegessen? Wie waren die drauf? Haben die Krebs gehabt? Ja, nein. Das ist quasi ein Merkmal dafür, ob du mehr zahlst für deine Versicherung oder eben weniger. Und wer dann biologisch risikobehaftet ist, zahlt einfach mehr oder bekommt eben vielleicht eine andere Behandlung. Also ich möchte jetzt nicht wirklich richtig böse machen, aber so nach dem Motto, alle deine Vorfahren sind sowieso mit 75 gestorben. Warum sollen wir dir jetzt noch eine Krebstherapie zahlen? Du bist 74. Und deswegen bin ich auch hier und irgendwie so dieses, es macht mir Angst, weil da steckt so viel dahinter. Und ich fand das Beispiel von dir super, weil eigentlich sollte jeder sich so einen Agent selber bauen und dann verstehen, was es leisten kann, um somit eben auch größere Modelle kritisch betrachten zu können. Aber sowas wie jetzt diese epigenetischen Marker, das sieht keiner von uns, das findet irgendwo statt, das wird nicht öffentlich diskutiert und da haben wir auch keinen Zugriff drauf. Ich möchte nochmal einen Punkt reinbringen, weil es geht ja immer um Entscheiden. Am Ende soll der Mensch entscheiden. Und was mir mal da sehr geholfen hat, ist von jemandem, den ich leider nicht nennen kann, weil ich nicht mehr weiß, wer es war. Der hat den Unterschied gemacht zwischen einer Wahl treffen und etwas entscheiden. Und die Wahl treffen heißt, wenn Weg A mit 80% richtig ist und Weg B mit 60% richtig ist, dann ist die Wahl Weg A. Das ist keine Entscheidung. Das ist einfach nur die Wahl der besseren Optionen. Und das ist das, was alle haben wollen. Das, was eine Entscheidung ist, ist 80% Weg A, 60% Weg B, aber hat die schöne Aussicht oder bringt mich sportlich weiter oder hat irgendwann einen anderen Aspekt, der aber halt 60% oder gar nicht gewertet wird. Den Weg zu gehen ist eine Entscheidung. Zu sagen, ich entscheide mich bewusst gegen den Vorschlag von wem auch immer, ob der von KI oder von meinem besten Freund oder vom Doktor kommt. Also diese Unterscheidung zwischen treffe ich eine Wahl der besten vorgeschriebenen Möglichkeiten mit allem, was ich da analysieren kann, KI kann mir super helfen dabei, oder entscheide ich mich bewusst, das kann auch für dieses Ergebnis sein, aber bin ich wirklich so selbstständig, mich für oder gegen etwas zu entscheiden, obwohl vielleicht alles dagegen spricht. Wenn ich mir heute Regierungen anschaue, wenn ich mir heute Firmenlenker anschaue, da wird nichts mehr entschieden. Es wird nur noch gewählt. Und zwar die Variante, wo ich die meisten Wähler kriege, wo ich am schnellsten Geld verdiene, wo ich am schnellsten effizient werde oder so. Und da wollen die einfach nur bessere Berater für ihre Wahl haben. Aber um an deinen Punkt nochmal anzuknüpfen, das war jetzt aus dem Thema Gesundheitswesen, nichts anderes passiert im Recruiting oder bei der Karriereentscheidung. Also da gibt es ja auch schon zig Studien im Recruiting, kein Bild dabei, kein Name dabei, kein Geburtsdatum dabei, da werden andere Recruitingentscheidungen getroffen. Also von dem her ist das schon immer ein Thema gewesen und die ersten drei Sekunden, du gefällst mir, gefällst mir nicht, die Entscheidung machen wir alle und wir haben unsere Schubladen, den oder diejenige hole ich mir ins Team oder hole ich mir nicht ins Team an der Stelle oder den oder diejenige befördern wir, geben wir die Promotion oder geben wir nicht. Da spielen schon immer solche Faktoren quasi eine Rolle. Aber da bin ich auch überzeugt, dass da eben tatsächlich eben die KI oder die Data Analytics da einfach noch urteilsfreier Vorschläge entsprechend machen wird. Also auch alleine das Thema, was wir haben im Gender, dass Frauen eben nicht so eher für die Promotion, für die Karriere ausgewählt werden als Männer, wird sich verändern, weil einfach mehr Daten und Fakten auf dem Tisch liegen, was eben nicht entsprechend kommuniziert wurde, was eben nicht diskutiert wurde. Die Datenfakten werden es dann nachher entscheiden. Dass solche medizinischen Entscheidungen, Versicherungsentscheidungen etc. auf Basis von irgendwelchen Informationen getroffen werden, ist ein schwieriges Thema. Warum sollte ein Raucher, ein Trinker, ein was weiß ich, vorbelasteter Mensch jetzt plötzlich mehr in die Gesundheitskasse zahlen als wir, die möglicherweise jeden Morgen 10 Kilometer joggen? Das ist die ethische Diskussion, die wir machen. Also weil ich sage mal, derjenige, der sich sportlich fit hält und damit locker 90 wird, trägt ja den Kettenraucher einfach mal so mit im Gesundheitswesen. Da gab es noch eine, Joachim, ja genau. Ja genau, ich wollte dann noch was dazu sagen, weil, also einmal kommt mir das, wie ich das von Harald verstanden habe, dass man noch eine Unterscheidung treffen kann, weil sie sind eigentlich das, was den Menschen ausmacht. Und ich kenne da das gute Begriff Stimmigkeit, das Gefühl von Stimmigkeit und das ist kein Faktum, das ist ein Gefühl. Und auf der einen Seite, die KI lernt immer mehr Fakten zu verarbeiten und der Mensch, und das macht den Menschen, nennen das ein ganzes Spiel aus. Ich glaube, der Mensch sollte lernen, seine Stimmigkeit zu erfüllen und zu unterscheiden und unterscheiden zu lernen, ob das jetzt ein Triggerpunkt ist, der quasi ins Leid führt oder ob das ist, wo ich sage, da will ich hin und das ist mir wichtig und deswegen entscheide ich auch für das, was die Kringer. Wahrscheinlichkeit hat. Und das ist auch, würde ich sagen, also ich würde auch aufrufen, als Mensch, Mensch lerne das Menschliche. Und das ist meines Erachtens das Fühlen und dieser Umgegang mit dem, was das Innere. Und es nutzt nichts zu sagen, der Mensch ist doof, weil er die Fakten nicht kennt. Und der Mensch ist immer komisch, weil er irgendwie komisch entscheidet, sondern Unterscheidungsfähigkeit zu lernen. Das ist auch eine Wissenslücke übrigens, meine ich. Und es gibt den Achtsamkeitslern, aus der eine Richtung hilft. Herzlichen Dank, Jörg. Ein guter Punkt. Harald? Weil du das jetzt auch angesprochen hast, ich würde auch das noch mal sogar eine Stufe weiterspinnen. Ich bin ja eigentlich jemand, der gerne Praktiker ist. Ich probiere die Sachen gern aus und ich bin Logiker erzogen sozusagen. Ich muss es mir erklären können und ich mag Fakten sehr gerne, sagen wir es mal so. Und gleichzeitig könnte man ja mal sich anschauen, Wir waren vorher bei dem Thema Gesunderhaltung, Krankheiten und so weiter. Jetzt haben wir die Medizin, wird immer besser. Wir haben diese ganzen Assistenten und die sorgen dafür, dass wir ja gar nicht mehr krank werden, sondern eigentlich wäre deren Ziel, uns gesund zu erhalten. Jetzt gibt es ja, ich will jetzt nicht sofort sagen, dass ich die voll vertrete, aber ich habe sie mir mal angeschaut. Es gibt ja eine Bewegung, die sagt, der Mensch, wenn er auf die Erde kommt, soll bestimmte Dinge erleben, um daran zu wachsen. Und das sind auch Krankheiten. Das heißt, das muss man sehr stark diskutieren, aber das geht halt her, wenn jemand auf die Welt kommt und zum Beispiel mit einer Behinderung oder mit irgendwas gepeinigt ist sozusagen, dann ist es in seinem Leben, wenn man diese Philosophie mal verfolgt, die Aufgabe zu wachsen. Wenn wir das jetzt alles rausnehmen, und das kannst du heute schon sehr, sehr stark beobachten, wir haben da draußen wenig Leute noch mit Behinderung durch die Fußgängerzone laufen. Die sind alle aus dem Stadtbild raus. Es gibt so Strömungen, die sagen, das schadet dem Glücksgefühl der Gesellschaft. Also lauter so ganz komische Thesen. Aber das passiert ja überall. Das heißt, wir versuchen uns immer mehr in so einen idealen Glückszustand zu bringen. Und wenn du dir das aber anschaust, dann sind wir immer weiter weg davon. Wir haben immer schlechtere Beziehungen. Wir haben immer weniger von dem, was wirklich, wirklich zählt. Weil wir alles optimieren aufgrund eines idealisierten Standardbildes. Und die Frage ist, ist nicht, jetzt komme ich wieder zurück zur Komplexität und Natur, ist nicht Unverfügbarkeit, gibt es ein tolles Buch darüber, oder ist nicht die Anstrengung, das, was den Erfolg dann wirklich schön macht, ist nicht das Leiden sozusagen auch irgendwie notwendig, damit man den Glückszustand so maximal auskosten kann. Wenn du aber ständig optimiert wirst, dass das alles rausgenommen wird, dann ist das so ein Zombie-Leben, das so vor sich hingeht, mit ohne Höhen, ohne Tiefen natürlich, Aber so richtig lebenswert vielleicht auch nicht mehr. Das ist jetzt ein bisschen sehr, aber... Wir haben 47. Zeit zum Wechseln. Danke für die Diskussion. Danke für die Teilnahme. Und wie gesagt, die Folien werde ich noch teilen. Vielen Dank. Wir haben auch eine Art der Welt, die sich in dieser Welt beschäftigen. Und die sind auch ausgedreffend im Sinne der Arbeit. Das ist ja auch ein Grund, und das ist ja auch ein Grund. Das siehst du auch hier unten, dass man den Buch bringt, wenn man die Nachbindel rufen. Ja, das wird schon weitergegeben. Und das ist ja auch ein Grund. Ja? Also das ist aktiv. Ich glaube, dass es nicht mehr als Assistenzfunktion gibt, es ist nicht mehr Assistenzfunktion, sondern es ist kein Liebling.